---
marp: true
theme: default
style: |
    section { background-color: #fff; font-family: Arial, sans-serif; font-size:20px}
    h1 { color: #1c5fa8; }
    h2 { color: #2c75d6; }
    table { width: 100%; font-size: 0.9em; }
    footer { color: #666; font-size: 0.7em; }
header: Рекомендательные системы
footer: БГУ ФПМИ ФМИиС
paginate: true
---

<!-- _class: title -->
# **Рекомендательные системы: от теории к преодолению "холодного старта"**
### Коллаборативная фильтрация, матричные разложения и решение ключевых проблем

---



1.  **Введение:** Зачем нужны рекомендации? Постановка задачи.
2.  **Коллаборативная фильтрация:** User-Based и Item-Based подходы.
3.  **Матричные разложения:** SVD и ALS.
4.  **Гибридные подходы.**
5.  **Проблема "холодного старта".**
6.  **Современные тренды (Neural, FAISS).**
7.  **Заключение.**

---

### **Часть 1: Введение**

## Зачем нужны рекомендательные системы?

Польза рекомендательных систем очевидна, как для пользователей, так и для бизнеса. Рекомендация нужного товара, о нужности которого человек мог прямо сейчас не думать, очевидна: клиент получает нужную услугу, бизнес получает деньги.

![bg right:50% w:600](https://mobiplus.co/wp-content/uploads/2023/06/companiesrecom-1024x448.png)

---

## Постановка задачи

*   **Дано:**
    *   Множество пользователей `U`.
    *   Множество предметов (товаров, фильмов, песен) `I`.
    *   Матрица взаимодействий `R [U x I]`.
*   **Задача:** Для пары (user, item) предсказать **оценку** или **вероятность взаимодействия**.
*   **Цель:** Найти для каждого пользователя **топ-N предметов**.

![bg right w:650](https://miro.medium.com/v2/resize:fit:1400/1*omYTxakC8y4dz-fvpM1Lug.jpeg)

---

## Типы данных и Фильтрации

*   **Явная обратная связь (Explicit Feedback):**
    *   Оценки, лайки.
    *   *Плюсы:* Понятны. *Минусы:* Мало данных, смещенность данных.
*   **Неявная обратная связь (Implicit Feedback):**
    *   Просмотры, клики, покупки.
    *   *Плюсы:* Много данных. *Минусы:* Шум.

**Типы подходов:**
*   **Контентная фильтрация:** На основе свойств предметов.
*   **Коллаборативная фильтрация (CF):** На основе поведения *других* пользователей. 

---

### **Часть 2: Коллаборативная фильтрация**

## Идея Коллаборативной фильтрации

**Ключевой принцип:** "Схожие пользователи предпочитают схожие предметы".

**Два основных подхода:**
1.  **User-Based CF:** "Найди пользователей, похожих на меня..."
2.  **Item-Based CF:** "Найди товары, похожие на те, что мне нравятся..."


---

## User-Based Collaborative Filtering

**Шаги:**
1.  Найти **k-наиболее похожих пользователей** (neighbors). Метрика: **Косинусная схожесть**.
2.  Вычислить **взвешенную среднюю оценку** от этих соседей.
3.  Рекомендовать items с самыми высокими предсказанными оценками.

**Проблема:** Вычислительно дорого для миллионов пользователей.

![Косинусная схожесть](https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg)

---

## Item-Based Collaborative Filtering (Amazon)

**Шаги:**
1.  Вычислить попарные схожести **между предметами**.
2.  Для пользователя: посмотреть на его историю.
3.  Просуммировать схожести предмета с предметами из истории.

**Плюсы:**
*   Items меняются реже. Матрицу `Sim` можно пересчитывать нечасто.
*   Стабильнее и быстрее, чем User-Based.

---

## Проблемы "Наивной" Коллаборативной фильтрации

*   **Разреженность (Sparsity):** Матрица `R` на 99% пустая.
*   **Маcштабируемость:** Сложность `O(N^2)`.
*   **"Холодный старт" (Cold Start):** Нет данных для новых пользователей/items.

![Разреженная матрица](https://cmdlinetips.com/wp-content/uploads/2018/03/Sparse_Matrix.png)

---

### **Часть 3: Матричные разложения**

## Идея Matrix Factorization (MF)

**Цель:** Преодолеть разреженность и повысить точность.
**Интуиция:** Представить и пользователей, и items в виде векторов в **едином латентном пространстве**.

**Латентные факторы:** Скрытые признаки (например, для фильмов: "степень серьёзности", "количество экшна").

![Латентное пространство](https://miro.medium.com/1*cxk57mds9jUOKiFYOa5Org.png)

---

## SVD (Singular Value Decomposition)

**Математическая основа:** `M = U * D * V^T`

*   `U` - связь пользователей с факторами.
*   `D` - важность каждого фактора.
*   `V^T` - связь предметов с факторами.

**Применение:** Берем усечённое разложение `M ≈ U_d * D_d * V_d^T`.

![SVD разложение w:900](https://cdn.prod.website-files.com/5b1d427ae0c922e912eda447/5feb62f53532cb257a8f901d_open_compressed.jpg)

---

## ALS (Alternating Least Squares)

**Проблема:** В матрице `R` много пропусков. Классический SVD неприменим.
**Решение: ALS.**

**Алгоритм:**
1.  **Фиксируем** вектора предметов `Q`, оптимизируем для `P`.
2.  **Фиксируем** вектора пользователей `P`, оптимизируем для `Q`.
3.  Попеременно повторяем.

**Плюсы:** Отлично работает с разреженными матрицами, распараллеливается.

![ALS итерации w:500](https://sandipanweb.wordpress.com/wp-content/uploads/2016/08/algo2.png?w=640)

---

## Как выглядит предсказание?

*   У пользователя $u$ есть вектор $p_u$.
*   У предмета $i$ есть вектор $q_i$.
*   **Предсказанная оценка:** $\hat r_{ui} = p_u * q_i^T$
*   **Рекомендация:** Вычислить оценку для всех предметов, отсортировать, взять топ-N.

---

## Проблема "Холодного старта" (Cold Start)

**Суть:** Невозможно дать персонализированные рекомендации для новых пользователей или новых предметов.

**Три типа:**
1.  **Новый пользователь (User Cold Start).**
2.  **Новый предмет (Item Cold Start).**
3.  **Новая система (System Cold Start).**

---

## Решение для User Cold Start

1.  **Неперсонализированные рекомендации:**
    *   Топ-N самых популярных предметов.
2.  **Сбор явных предпочтений:**
    *   Онбординг: "Выберите 5 любимых жанров".
3.  **Использование контекстной информации:**
    *   Геолокация, устройство, время суток.

---

## Решение для Item Cold Start

1.  **Контентные признаки:**
    *   Использовать атрибуты item'а (описание, жанр, автор).
2.  **Рекомендация "по схожести контента":**
    *   Похожие товары на основе метаданных.
3.  **Продвижение новых предметов:**
    *   Скидки, пометка "Новинка".

---

### **Часть 5: Современные тренды и заключение**

## Нейросетевые подходы (Neural CF)

**Идея:** Заменить скалярное произведение на нейронную сеть.
**Архитектура:** Two-Tower (Двухбашенная) модель.

*   **Одна "башня"** кодирует пользователя.
*   **Вторая "башня"** кодирует item.
*   Вектора объединяются для предсказания.

**Плюсы:** Учет нелинейных взаимодействий и side-информации.

![bg right w:500](https://miro.medium.com/v2/resize:fit:1200/1*JbK2gjfLC4IFoM6AVWLaUQ.png)

---

## Ключевые выводы

1.  **Коллаборативная фильтрация** — ядро систем, основанное на "мудрости толпы".
2.  **Матричные разложения** — мощный инструмент для работы с разреженными данными.
3.  **Проблема "холодного старта"** решается через **гибридные подходы** и **контентные признаки**.
4.  Нет идеального алгоритма. Выбор зависит от **задачи и данных**.

---

## Что почитать?

*   **Классика:** "Recommender Systems: The Textbook" by Charu C. Aggarwal.
*   **Статья Netflix Prize:** "Matrix Factorization Techniques for Recommender Systems" (2009).

---

## Вопросы?

![Questions](https://media.tenor.com/lx2WSGRk8bcAAAAC/puppy-big-eyes.png)
