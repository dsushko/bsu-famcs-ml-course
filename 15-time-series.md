---
marp: true
theme: default
style: |
    section {
        font-family: Arial, sans-serif; font-size:20px;
    }
    h1 {
        color: #0055A4;
    }
    h2 {
        color: #0072CE;
    }
    strong {
        color: #E63946;
    }
header: Временные ряды
footer: БГУ ФПМИ ФМИиС
paginate: true
---

<!-- _class: title -->
# **Временные ряды: от классических моделей до практических тонкостей**
## Стационарность, ARIMA, Prophet, Деревья, Кластеризация и проблемы валидации

![bg right:40% w:400](https://miro.medium.com/v2/resize:fit:1400/1*J5qNdJkYGa9kAY8j4jfUOg.png)

---



1. **Введение:** Что такое временные ряды? Ключевые компоненты.
2. **Основные концепции:** Стационарность, автокорреляция.
3. **Золотые правила валидации моделей** (самая важная практическая часть).
4. **Классические модели:** ARIMA.
5. **Современные подходы:** Prophet, Neural Prophet.
6. **Ансамбли и деревья:** Решающие деревья для временных рядов.
7. **Кластеризация временных рядов.**
8. **Проблема "холодного старта".**
9. **Заключение и выводы.**

---

### **Часть 1: Основные концепции**

## Что такое временной ряд?

*   **Определение:** Упорядоченная последовательность точек данных, собранных в последовательные моменты времени.
*   **Примеры:**
    *   Ежедневная цена акции.
    *   Еженедельные продажи магазина.
    *   Помесячная температура воздуха.
*   **Цель анализа:** Понимание структуры, прогнозирование будущих значений.

![bg right:30% w:300](https://www.investopedia.com/thmb/7bYaaPcXvxL4NvYF5K2pXKJtNwM=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/Term-Definitions_Time-Series--f993c67c62f14b4e9a5c4b6a8996c69c.jpg)

---

## Ключевые компоненты временного ряда

**Декомпозиция ряда:**
*   **Тренд (Trend):** Долгосрочное направление ряда.
    *Пример: общий рост выручки компании.*
*   **Сезонность (Seasonality):** Периодические колебания.
    *Пример: пики продаж мороженого летом.*
*   **Цикл (Cycle):** Колебания без строгой фиксированной частоты.
*   **Шум/Остаток (Residual):** Случайная, необъяснимая компонента.

![bg right:50% w:600](https://i.bigenc.ru/resizer/resize?sign=ToE1Hl5LVtzlMlcIiZ8fHg&filename=vault/3c99548643e8d26fcd8acafe0761731f.webp&width=1200)

---

## Стационарность — краеугольный камень

*   **Почему важна?** Большинство классических моделей работают со стационарными рядами.
*   **Определение:** Его статистические свойства (среднее, дисперсия) постоянны во времени.
*   **Как добиться стационарности?**
    *   **Дифференцирование (d=1):** `Y_t = original_t - original_{t-1}`. Убирает тренд.
    *   **Логарифмирование:** Стабилизирует дисперсию.

![bg right:40% w:500](https://miro.medium.com/0*ysppg4qDuwJFmwcZ.jpeg)

---

## Автокорреляция (ACF) и Частичная автокорреляция (PACF)

*   **ACF:** Корреляция ряда с самим собой на разных лагах. Обнаруживает сезонность.
*   **PACF:** Корреляция между рядом и его лагом, при устранении влияния всех промежуточных лагов. Критична для ARIMA.

**Как выглядит:**
![bg right w:600](https://i.sstatic.net/8ECds.png)

---

### **Часть 2: Валидация моделей (самое важное!)**

## Модель должна тестироваться так, как она будет использоваться.

*   **Ошибка:** Случайное разбиение на train/test НЕДОПУСТИМО.
*   **Правило:** Сохраняй временной порядок. Модель не должна "заглядывать в будущее".
*   **Метод:** **Rolling Window / Walk-Forward Validation.**

![bg right w:600](https://media.licdn.com/dms/image/v2/D5612AQG4IVWx1txMxw/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1729704761810?e=2147483647&v=beta&t=1p0i0souTJtiaPCpMrx8_xaWTCXlNbhPziI-HXCexW4)

*пример у доски с алконом*

---

## Тонкости реальных данных (Data Leakage)

*   **Проблема 1: "Обновляемые на ходу" данные.**
    *   *Пример:* Баланс пользователя в БД. Его историческое значение может измениться. 
    * *Ситуация*: Попытка моделирования предсказаний с даты 01.01.2026 на следующий день и через месяц, при условии редактируюшихся данных на промежутке этого месяца. При обучении через месяц получим data leak.
*   **Решение: Фиксация снепшотов (Snapshotting).**
    *   Регулярно сохранять состояние всех признаков и таргета.
*   **Проблема 2: Признаки с задержкой доступности.**
    *   *Пример:* Выручка за день доступна только к обеду следующего дня.
*   **Решение:** Тщательно согласовывать временные метки всех признаков.

---

### **Часть 3: Классические модели**

## Модель ARIMA (AutoRegressive Integrated Moving Average)

*   **"Золотой стандарт"** прогнозирования.
*   **AR(p) - Авторегрессия:** Зависимость от `p` предыдущих значений.
*   **I(d) - Интегрирование:** Количество дифференцирований.
*   **MA(q) - Скользящее среднее:** Зависимость от ошибок прогноза.
*   **Полная запись:** ARIMA(p, d, q)

**Как подобрать параметры?**
*   **d:** Тест Дики-Фуллера.
*   **p:** График **PACF**.
*   **q:** График **ACF**.

![bg right w:650](https://otexts.com/fpp2/fpp_files/figure-html/isms-1.png)

---

## Плюсы и минусы ARIMA

*   **Плюсы:**
    *   Хорошо интерпретируема.
    *   Широко известна.
*   **Минусы:**
    *   Требует стационарности.
    *   Плохо работает с сильным шумом.
    *   Сложность ручного подбора.

---

### **Часть 4: Современные модели от Facebook**

## Prophet

**Философия:** Простая, автоматизированная и устойчивая модель.

`y(t) = g(t) + s(t) + h(t) + ε_t`
*   `g(t)` — тренд.
*   `s(t)` — сезонность (Фурье).
*   `h(t)` — эффект праздников.
*   **Не требует стационарности.**

![bg right:40% w:400](https://facebook.github.io/prophet/static/quick_start_files/quick_start_12_0.png)

---

## Neural Prophet

Модель объединяет интерпретируемость классических статистических методов с гибкостью нейронных сетей. Это развитие модели Prophet на основе PyTorch.

Основная формула (аддитивная модель)
$$y(t)=T(t)+S(t)+R(t)+L(t)+F(t)+ϵ $$
$y_t$ — прогнозируемое значение в момент времени $t$.
$T(t)$ — Тренд. Моделируется кусочно-линейной функцией или с помощью нейросети (AR-Net).
$S(t)$ — Сезонность. Задается через преобразование Фурье (ряды Фурье) для учета периодичности.
$R(t)$ — Эффект праздников/событий. Пользователь задает даты событий.
$L(t)$ — Авторегрессионная компонента. Моделирует зависимость от своих собственных лагов ($y_{t-1}, y_{t-2}, ...$) с помощью AR-Net (нейросеть).
$F(t)$ — Ковариаты (дополнительные признаки). Может использовать будущие известные (e.g., промо-акции) или прошлые признаки.
$\epsilon_t$ — Шум. Ошибка модели, которую невозможно объяснить.

---

### **Часть 5: Деревья и ансамбли**

## Решающие деревья для временных рядов

**Идея:** Превратить прогнозирование **временного ряда** в задачу **регрессии**.

**Какие признаки создавать?**
*   Лаги исходного ряда (`lag_1`, `lag_7`, ...).
*   Скользящие статистики: среднее, std.
*   Признаки времени: час, день недели.
*   Признаки событий: праздники.

Важно помнить! У деревьев будут проблемы с предсказанием тренда. Поэтому, скорее всего, потребуется использовать комбинацию моделей:

1. Модель предсказания тренда (например, линейная регрессия)
2. Модель предсказания остальных деталей ряда (XGBoost, etc.)

---

### **Часть 7: Проблема холодного старта**

## Что такое "Холодный старт" (Cold Start)?

**Проблема:** Построить прогноз для объекта, по которому **очень мало исторических данных**.

**Примеры:**
*   Прогноз спроса для нового товара.
*   Прогноз нагрузки для нового сервера.

---

## Стратегии решения

1.  **Использование мета-признаков:**
    *   Найти "похожие" объекты с богатой историей (по категории, цене, бренду).
    *   Использовать их данные для прогноза (в точностью до масштаба - предсказывается траектория и каждый отдельный продукт масштабируется домножением на число).
2.  **Иерархическое прогнозирование:**
    *   Сделать прогноз на уровень категории (прогноз суммы всех товаров из категории).
    *   Распределить прогноз по новым товарам - модель, предсказывающая долю продукта в категории на определённую дату (от 0 до 1).
    *   Прогноз модели №1 умножается на прогноз модели №2 - получается прогноз для конкретного продукта.

---

### **Часть 6: Кластеризация временных рядов**

**Задача:** Найти группы похожих временных рядов.

**Основное применение**
  - улучшать качество текущих предсказаний на основе найденных закономерностей.
  - решать проблему холодных стартов - когда выходит новый продукт, который по признакам похож на некоторые прошлые запущенные продукты. Таким образом вместо отсутствия предсказаний мы получаем предсказание в хорошем приближении, которое еще и будет обновляться в дальнейшем с поступлением данных.
  - получить понимание, какие категории можно объединять, а какие не стоит.

---

## Подходы к кластеризации

1.  **На основе признаков (Feature-based):**
    *   Извлекают стат. признаки (среднее, дисперсия).
    *   Кластеризуют вектора (K-Means).
2.  **На основе формы (Shape-based):**
    *   **DTW (Dynamic Time Warping):** Учитывает временную динамику и фазовый сдвиг.
3.  **На основе моделей (Model-based):**
    *   Строят модель (ARIMA) для каждого ряда.
    *   Кластеризуют вектора параметров.

![bg right w:500](https://towardsdatascience.com/wp-content/uploads/2020/02/1uFicSZjqkNBfsyrsJw7J9g.jpeg)

---

### **Заключение**

## Сравнительная таблица методов

| Метод               | Плюсы                          | Минусы                             | Идеальный кейс                     |
|---------------------|--------------------------------|------------------------------------|------------------------------------|
| **ARIMA**           | Интерпретируемость, стандарт   | Требует стационарности             | Короткие стационарные ряды         |
| **Prophet**         | Автоматизация, праздники       | Черный ящик                        | Бизнес-ряды с сезонностью          |
| **Neural Prophet**  | Точность, внешние признаки     | Медленнее                          | Сложные ряды с контекстом          |
| **Деревья (GBM)**   | Точность, внешние признаки     | Риск data leakage                  | Прогнозирование с богатым контекстом |

---

## Ключевые выводы

1.  **Правильная валидация (Rolling Window) важнее выбора модели.**
2.  Не существует "серебряной пули". Выбор зависит от данных и требований.
3.  **ARIMA** — классика, **Prophet** — для быстрого старта, **Gradient Boosting** — для максимальной точности.
4.  Проблема **холодного старта** решается через мета-признаки и иерархические модели.

---

## Что почитать?

*   **Книги:**
    *   Hyndman, R.J. & Athanasopoulos, G. *"Forecasting: Principles and Practice"* — [OTexts.com](https://otexts.com/fpp3/)
*   **Библиотеки Python:**
    *   `statsmodels`, `pmdarima` (ARIMA)
    *   `prophet`, `neuralprophet`
    *   `sktime`, `tslearn` (кластеризация)

**Спасибо за внимание!**
**Вопросы?**