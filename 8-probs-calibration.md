---
marp: true
theme: default
paginate: true
style: |
    section { font-family: Arial, sans-serif; font-size: 20px}
header: Калибровка и наивный Байес
footer: БГУ ФПМИ ФМИиС
---

<!-- _class: title -->
# **Задача оценивания вероятностей в ML**
## Калибровка предсказаний и наивный байесовский классификатор
**Ваше имя**

![bg right w:450](https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Very_Simple_Probability_Chart.svg/1280px-Very_Simple_Probability_Chart.svg.png)

---

### **Важность достоверных вероятностей**

## **Зачем нужны вероятности?**
# **Классификация — это не только метка**

*   **Метка (Label):** Спам / не спам
*   **Вероятность:** Насколько мы уверены? (Спам с вероятностью 97% vs 51%)
*   **Применение:**
    *   **Принятие решений:** Доверить ли решение алгоритму? (Если P > 0.9 — автоматически помечать как спам)
    *   **Расчет ожидаемой value:** В маркетинге, медицине, рисках
    *   **Последующая обработка:** Стоимость ошибок (False Positive vs False Negative)

---

## **Проблема: Не все модели дают хорошие вероятности**
# **"Уверенный" — не значит "точный"**

*   Некоторые алгоритмы (например, SVM, деревья) выдают **оценки вероятностей**, но они могут быть смещенными.
*   **Пример:** Модель всегда предсказывает P(класс=1) ≈ 0.9 или 0.1, но почти никогда 0.5. Это **плохо откалиброванные** вероятности.
*   **Хорошая вероятность:** Если модель говорит P=0.9, то в 90% случаев объект действительно должен относиться к этому классу.

![bg right w:400](https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Calibration_plot_example.svg/1280px-Calibration_plot_example.svg.png)

---

### **Калибровка вероятностей**

## **Что такое калибровка?**
# **Калибровка = Исправление смещения оценок**

*   **Цель:** Преобразовать "сырые" выходы модели (scores) в **достоверные вероятности**.
*   **Идея:** Научить эталонную модель (калибратор) предсказывать истинную вероятность по выходу основной модели.
*   **Область применения:** Чаще всего нужна для моделей, которые не строят вероятностную модель данных (SVM, бустинг, случайный лес).

---

## **Калибровочная кривая (Reliability Plot)**
# **Диагностика: как проверить калибровку?**

*   **По оси X:** Предсказанная вероятность (разбитая на бины, например, [0.0-0.1], [0.1-0.2]...).
*   **По оси Y:** Фактическая доля положительных примеров в этом бине.
*   **Идеальная калибровка:** Все точки лежат на диагональной линии.
*   **Перекалибровка:** Точки ниже диагонали (модель переоценивает).
*   **Недокалибровка:** Точки выше диагонали (модель недооценивает).

![w:700](https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_001.png)

---

## **Методы калибровки: Platt Scaling**
# **Логистическая регрессия на выходах модели**

*   **Идея:** Настроить логистическую регрессию, где признаком является "сырой" выход немодели (score), а целевая переменная — истинная метка.
*   **Формула:** `$P(y=1 | f) = \frac{1}{1 + \exp(A \cdot f + B)}$`
*   **Плюсы:** Простота, мало параметров.
*   **Минусы:** Предполагает сигмоидную форму искажения.
*   **Лучше всего подходит для:** SVM и других моделей с похожим поведением.

---

## **Методы калибровки: Isotonic Regression**
# **Непараметрический подход**

*   **Идея:** Найти монотонно возрастающую функцию, которая лучше всего приближает калибровочную кривую.
*   **Плюсы:** Гибче, чем Platt Scaling. Может исправить более сложные искажения.
*   **Минусы:** Требует больше данных, склонен к переобучению на маленьких выборках.
*   **Лучше всего подходит для:** Больших датасетов и сложных искажений.

---

## **Практические аспекты калибровки**
# **Как не допустить утечку данных?**

*   **Важно:** Калибратор нужно обучать на **валидационной** выборке, а не на тестовой!
*   **Пайплайн:**
    1.  Разделить данные на Train / **Calibration** / Test.
    2.  Обучить модель на Train.
    3.  Получить прогнозы для Calibration set.
    4.  Обучить калибратор (Platt/Isotonic) на этих прогнозах и истинных метках.
    5.  Оценить качество на Test set.
*   **Встроенная калибровка:** `CalibratedClassifierCV` в sklearn.

![bg right w:400](https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_curve_001.png)

---

### **Наивный байесовский классификатор**

## **Вероятностная основа классификации**
# **Теорема Байеса в Machine Learning**

### **Формула:** 
$$P(Y | X) = \frac{P(X | Y) \cdot P(Y)}{P(X)}$$

*   **P(Y | X)** — апостериорная вероятность (наша цель).
*   **P(X | Y)** — правдоподобие (likelihood).
*   **P(Y)** — априорная вероятность (prior).
*   **P(X)** — evidence (нормирующая константа, одинакова для всех классов).

![bg right w:300](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Bayes%27_Theorem_MMB_01.jpg/1024px-Bayes%27_Theorem_MMB_01.jpg)

---

## **Идея наивного байесовского классификатора**
# **"Наивное" предположение о независимости**

*   **Задача:** Оценить P(X | Y) для многомерного X = (x₁, x₂, ..., xₙ) сложно.
*   **Упрощение (Наивное):** Признаки условно независимы при данном классе Y.
*   **Формула:** `$P(X | Y) = P(x_1 | Y) \cdot P(x_2 | Y) \cdot ... \cdot P(x_n | Y)$`
*   **Решение:** `$y = \arg\max_{y} P(y) \cdot \prod_{i=1}^{n} P(x_i | y)$`

---

## **Почему "наивный"? Плюсы и минусы**
# **Сильные и слабые стороны**

*   **Минусы:**
    *   Признаки редко бывают независимыми -> это сильное допущение.
    *   Из-за этого оценки вероятностей часто **плохо откалиброваны**.
*   **Плюсы:**
    *   Чрезвычайно **быстрый** в обучении и предсказании.
    *   Хорошо работает с **высокомерными** данными (например, текст).
    *   **Интерпретируемый.**
    *   Часто показывает хорошее качество **даже при нарушении предположения** о независимости.

---

## **Разновидности наивного Байеса**
# **Для разных типов данных**

*   **GaussianNB:** Для непрерывных признаков. Предполагает нормальное распределение P(x_i | y).
*   **MultinomialNB:** Для дискретных счетов (частоты слов в тексте).
*   **BernoulliNB:** Для бинарных признаков (0/1, например, наличие слова в тексте).
*   **CategoricalNB:** Для категориальных признаков.

![bg right w:350](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Gaussian_distribution_2.jpg/1280px-Gaussian_distribution_2.jpg)

---

## **Пример: Байесовский классификатор в спам-фильтрах**
# **Классическое применение**

*   **Y:** {Спам, Не спам}
*   **X:** Признаки — слова в письме.
*   **P(Спам):** Априорная вероятность (доля спама в почте).
*   **P(слово | Спам):** Вероятность встретить слово в спаме.
*   **Классификация:** Письмо — спам, если `P(Спам) * ∏ P(слово | Спам) > P(Не спам) * ∏ P(слово | Не спам)`

![bg left w:300](https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Spam_mail_folder.jpg/640px-Spam_mail_folder.jpg)

---

### **Связь концепций и заключение**

## **Калибровка вероятностей для Naive Bayes**
# **Комбинирование подходов**

*   Наивный Байес часто выдает крайние вероятности (близкие к 0 или 1).
*   **Решение:** Его выходы — отличный кандидат для последующей **калибровки** (например, с помощью Isotonic Regression).
*   **Результат:** Мы получаем скорость и интерпретируемость Naive Bayes и достоверные вероятности после калибровки.

![w:600](https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_004.png)

---

## **Выводы**
# **Ключевые takeaways**

*   **Вероятности** важнее меток для принятия решений.
*   Многие модели требуют **калибровки** для получения достоверных вероятностей.
*   **Platt Scaling** и **Isotonic Regression** — два основных метода.
*   **Наивный Байес** — простой, быстрый и эффективный классификатор, основанный на теореме Байеса.
*   Его главный недостаток (плохие вероятности) часто можно исправить калибровкой.

---

<!-- _class: title -->
# **Спасибо за внимание!**
## Вопросы?

**Ваша почта / Telegram**