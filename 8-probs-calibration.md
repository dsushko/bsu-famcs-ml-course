---
marp: true
theme: default
paginate: true
style: |
    section { font-family: Arial, sans-serif; font-size: 20px}
header: Калибровка и наивный Байес
footer: БГУ ФПМИ ФМИиС
---

<!-- _class: title -->
# **Задача оценивания вероятностей в ML**
## Калибровка предсказаний и наивный байесовский классификатор

---

### **Важность достоверных вероятностей**

## **Зачем нужны вероятности?**
# **Классификация — это не только метка**

*   **Метка (Label):** Спам / не спам
*   **Вероятность:** Насколько мы уверены? (Спам с вероятностью 97% vs 51%)
*   **Применение:**
    *   **Принятие решений:** Доверить ли решение алгоритму? (Если P > 0.9 — автоматически помечать как спам)
    *   **Расчет ожидаемой value:** В маркетинге, медицине, рисках
    *   **Последующая обработка:** Стоимость ошибок (False Positive vs False Negative)

---

## **Проблема: Не все модели дают хорошие вероятности**
# **"Уверенный" — не значит "точный"**

*   Некоторые алгоритмы (например, SVM, деревья) выдают **оценки "вероятностей"**, но не факт, что на самом деле это действительно вероятности.
*   **Пример:** Модель всегда предсказывает P(класс=1) ≈ 0.9 или 0.1, но почти никогда 0.5. Это **плохо откалиброванные** выходы модели.
*   **Хорошая вероятность:** Если модель говорит P=0.9, то в 90% случаев объект действительно должен относиться к этому классу.

---

### **Калибровка вероятностей**

## **Что такое калибровка?**
# **Калибровка = Исправление смещения оценок**

*   **Цель:** Преобразовать "сырые" выходы модели (scores) в **достоверные вероятности**.
*   **Идея:** Научить эталонную модель (калибратор) предсказывать истинную **вероятность** по выходу основной модели.
*   **Область применения:** Чаще всего нужна для моделей, которые не строят вероятностную модель данных (SVM, бустинг, случайный лес).


*Зачем так делать?* 
Это удобный способ добавить в модель больше explainability, а в частности - способ донести заказчику ещё немного информации о работе модели. Вероятность - интуитивно понятная идея. 
Это тот уровень математики, на котором заказчик точно в состоянии воспринимать информацию. В общем, как ни банально - это в основном для того, чтобы заказчик был доволен. А доволен заказчик - довольны все)

---

## **Калибровочная кривая (Reliability Plot)**
# **Диагностика: как проверить калибровку?**

*   **По оси X:** Предсказанная вероятность (разбитая на бины, например, [0.0-0.1], [0.1-0.2]...).
*   **По оси Y:** Фактическая доля положительных примеров в этом бине.
*   **Идеальная калибровка:** Все точки лежат на диагональной линии.
*   **Перекалибровка:** Точки ниже диагонали (модель переоценивает).
*   **Недокалибровка:** Точки выше диагонали (модель недооценивает).

![bg right w:600](https://scikit-learn.org/stable/_images/sphx_glr_plot_calibration_curve_001.png)

---

## **Методы калибровки: Platt Scaling**
# **Логистическая регрессия на выходах модели**

*   **Идея:** Настроить логистическую регрессию, где признаком является "сырой" выход немодели (score), а целевая переменная — истинная метка.
*   **Формула:** 
$$P(y=1 | f) = \frac{1}{1 + \exp(A \cdot f + B)}$$
*   **Плюсы:** Простота, мало параметров.
*   **Минусы:** Предполагает сигмоидную форму искажения.
*   **Лучше всего подходит для:** SVM и других моделей с похожим поведением.

---

## **Методы калибровки: Isotonic Regression**
# **Непараметрический подход**

*   **Идея:** Найти монотонно возрастающую функцию, которая лучше всего приближает калибровочную кривую.
*   **Плюсы:** Гибче, чем Platt Scaling. Может исправить более сложные искажения.
*   **Минусы:** Требует больше данных, склонен к переобучению на маленьких выборках.
*   **Лучше всего подходит для:** Больших датасетов и сложных искажений.

![bg right w:700](https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Isotonic_regression.svg/1200px-Isotonic_regression.svg.png)


---

# **Как калиброваться без дата лика?**

*   **Важно:** Калибратор нужно обучать на **валидационной** выборке, а не на тестовой!
*   **Пайплайн:**
    1.  Разделить данные на Train / **Calibration** / Test.
    2.  Обучить модель на Train.
    3.  Получить прогнозы для Calibration set.
    4.  Обучить калибратор (Platt/Isotonic) на этих прогнозах и истинных метках.
    5.  Оценить качество на Test set.
*   **Встроенная калибровка:** `CalibratedClassifierCV` в sklearn.

---

### **Наивный байесовский классификатор**

## **Вероятностная основа классификации**

### **Формула условной вероятности:** 
$$P(Y | X) = \frac{P(X | Y) \cdot P(Y)}{P(X)}$$

*   **P(Y | X)** — апостериорная вероятность (наша цель).
*   **P(X | Y)** — правдоподобие (likelihood).
*   **P(Y)** — априорная вероятность (prior).
*   **P(X)** — evidence (нормирующая константа, одинакова для всех классов).

![bg right w:300](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Bayes%27_Theorem_MMB_01.jpg/1024px-Bayes%27_Theorem_MMB_01.jpg)

---

## **Идея наивного байесовского классификатора**
# **"Наивное" предположение о независимости**

*   **Задача:** Оценить P(X | Y) для многомерного X = (x₁, x₂, ..., xₙ) сложно.
*   **Упрощение (Наивное):** Признаки условно независимы при данном классе Y.
*   **Формула:** $P(X | Y) = P(x_1 | Y) \cdot P(x_2 | Y) \cdot ... \cdot P(x_n | Y)$
*   **Решение:** $y = \arg\max_{y} P(y) \cdot \prod_{i=1}^{n} P(x_i | y)$

---

## **Почему "наивный"? Плюсы и минусы**
# **Сильные и слабые стороны**

*   **Минусы:**
    *   Признаки редко бывают независимыми -> это сильное допущение.
    *   Из-за этого оценки вероятностей часто **плохо откалиброваны**.
*   **Плюсы:**
    *   Чрезвычайно **быстрый** в обучении и предсказании.
    *   Хорошо работает с **высокомерными** данными (например, текст).
    *   **Интерпретируемый.**
    *   Часто показывает хорошее качество **даже при нарушении предположения** о независимости.

---

## **Разновидности наивного Байеса**
# **Для разных типов данных**

*   **GaussianNB:** Для непрерывных признаков. Предполагает нормальное распределение $P(x_i | y)$.
*   **MultinomialNB:** Для дискретных счетов (частоты слов в тексте).
*   **BernoulliNB:** Для бинарных признаков (0/1, например, наличие слова в тексте).
*   **CategoricalNB:** Для категориальных признаков.

---

## **Пример: Байесовский классификатор в спам-фильтрах**
# **Классическое применение**

*   **Y:** {Спам, Не спам}
*   **X:** Признаки — слова в письме.
*   **P(Спам):** Априорная вероятность (доля спама в почте).
*   **P(слово | Спам):** Вероятность встретить слово в спаме.
*   **Классификация:** Письмо — спам, если `P(Спам) * ∏ P(слово | Спам) > P(Не спам) * ∏ P(слово | Не спам)`